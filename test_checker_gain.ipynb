{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4d55d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de1cc6f",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8aeb456",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from psychrnn.backend.models.basic import Basic\n",
    "from psychrnn.backend.gain.gain2 import Basic2\n",
    "from psychrnn.backend.gain.loss import rt_mask_mse_06, rt_mask_mse_07, rt_mask_mse_08\n",
    "from psychrnn.tasks.checker import Checkerboard2AFC\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a223d068",
   "metadata": {},
   "source": [
    "### Initialize Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8bd5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = 'interactive'\n",
    "name = 'basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8603b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10\n",
    "tau = 50\n",
    "T = 3000\n",
    "N_batch = 50\n",
    "N_rec = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37c8fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Checkerboard2AFC(dt=dt, tau=tau, T=T, N_batch=N_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f4baf1",
   "metadata": {},
   "source": [
    "### Set up parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec8ed85",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_params = task.get_task_params()\n",
    "network_params['name'] = name\n",
    "network_params['N_rec'] = N_rec\n",
    "network_params['rec_noise'] = 0.1\n",
    "\n",
    "network_params[\"transfer_function\"] = tf.nn.relu\n",
    "network_params[\"output_transfer_function\"] = tf.nn.sigmoid\n",
    "\n",
    "network_params[\"loss_function\"] = \"rt_mask_mse\"\n",
    "network_params[\"rt_mask_mse\"] = rt_mask_mse_07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1502bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.destruct()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "model = Basic2(network_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28304ac6",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1124a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 25000\n",
    "train_params = {}\n",
    "train_params['save_weights_path'] =  \"./weihts/gain2_weights0_1\"\n",
    "train_params['training_iters'] = trials\n",
    "train_params['learning_rate'] = .001\n",
    "train_params['loss_epoch'] = 10\n",
    "train_params['save_training_weights_epoch'] = 1000 / N_batch\n",
    "network_params['gain_bound'] = [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63fc6dd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "losses, initialTime, trainTime = model.train(task, train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5119f05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.xlabel(\"Training Iteration\")\n",
    "plt.title(\"Loss During Training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf33fe3",
   "metadata": {},
   "source": [
    "### Test on 10000 trials to examine performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9bb136",
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = 5000\n",
    "batches = int(np.ceil(trials / N_batch))\n",
    "\n",
    "rnn_state = np.zeros((trials, task.N_steps, model.N_rec))\n",
    "rnn_out = np.zeros((trials, task.N_steps, model.N_out))\n",
    "\n",
    "coherence = np.zeros(trials)\n",
    "green_side = np.zeros(trials)\n",
    "target_onset = np.zeros(trials)\n",
    "checker_onset = np.zeros(trials)\n",
    "\n",
    "decision = np.zeros(trials)\n",
    "rt = np.zeros(trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12546f87",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for b in tqdm(range(batches)):\n",
    "    x, y, m, params = task.get_trial_batch()\n",
    "    outputs, states, inputs = model.test(x)\n",
    "    \n",
    "    start_index = N_batch * b\n",
    "    end_index = N_batch * (b + 1)\n",
    "    rnn_state[start_index:end_index] = states\n",
    "    rnn_out[start_index:end_index] = outputs\n",
    "    \n",
    "    thr = np.where(outputs > 0.7)\n",
    "    \n",
    "    for i in range(N_batch):\n",
    "        index = start_index + i\n",
    "        \n",
    "        coherence[index] = params[i][\"coherence\"]\n",
    "        green_side[index] = params[i][\"side\"]\n",
    "        target_onset[index] = params[i][\"target_onset\"]\n",
    "        checker_onset[index] = params[i][\"checker_onset\"]\n",
    "        \n",
    "        thr_time = thr[1][thr[0]==i][0] if sum(thr[0]==i) > 0 else outputs.shape[1]\n",
    "        thr_unit = thr[2][thr[0]==i][0] if sum(thr[0]==i) > 0 else np.argmax(outputs[i, -1])\n",
    "        decision[index] = thr_unit\n",
    "        rt[index] = thr_time*task.dt - target_onset[index] - checker_onset[index]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4971da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#onsets = [p[\"onset_time\"] for p in params]\n",
    "onsets = target_onset[-N_batch:] + checker_onset[-N_batch:]\n",
    "rts = rt[-N_batch:]\n",
    "for i in range(10):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, 3000, 10), inputs[i, :, 0])\n",
    "    plt.plot(np.arange(0, 3000, 10), inputs[i, :, 1])\n",
    "    plt.plot(np.arange(0, 3000, 10), inputs[i, :, 2])\n",
    "    plt.plot(np.arange(0, 3000, 10), inputs[i, :, 3])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, 3000, 10), outputs[i, :, 0])\n",
    "    plt.plot(np.arange(0, 3000, 10), outputs[i, :, 1])\n",
    "    \n",
    "    plt.vlines(onsets[i], 0, 1)\n",
    "    plt.vlines(onsets[i] + rts[i], 0, 1)\n",
    "    plt.hlines(0.7, 0, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86628168",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correct_side = np.array([gs if coh > 0 else abs(gs-1) for coh, gs in zip(coherence, green_side)])\n",
    "green_decision = np.array([int(dec == gs) for dec, gs in zip(decision, green_side)])\n",
    "checker_df = pd.DataFrame({'trial' : np.arange(trials),\n",
    "                           'coherence' : coherence,\n",
    "                           'coherence_bin' : np.round(coherence, 1),\n",
    "                           'green_side' : green_side,\n",
    "                           'correct_side' : correct_side,\n",
    "                           'target_onset' : target_onset,\n",
    "                           'checker_onset' : checker_onset,\n",
    "                           'decision' : decision,\n",
    "                           'green_decision' : green_decision,\n",
    "                           'decision_time' : rt,\n",
    "                           'correct_decision' : (decision == correct_side).astype(int)})\n",
    "checker_mean = checker_df.groupby('coherence_bin').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2bff71",
   "metadata": {},
   "outputs": [],
   "source": [
    "checker_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b6ab43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(checker_mean['coherence_bin'], checker_mean['green_decision'])\n",
    "plt.scatter(checker_mean['coherence_bin'], checker_mean['green_decision'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(checker_mean['coherence_bin'], checker_mean['decision_time'])\n",
    "plt.scatter(checker_mean['coherence_bin'], checker_mean['decision_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f676836b",
   "metadata": {},
   "source": [
    "# RT within coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992cc198",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0.9,0.7,0.5,0.3,0.1,0]:\n",
    "    a = checker_df['coherence_bin'] == i\n",
    "    groupCo = checker_df.loc[a,:]\n",
    "    RT = groupCo[\"decision_time\"]\n",
    "    plt.figure()\n",
    "    plt.hist(RT)\n",
    "    plt.title(\"Coherence: \" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c862a6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s = tf.zeros((1,100), dtype=tf.bool)\n",
    "# testR = tf.random.uniform(tf.shape(input=s), minval=1, maxval=2, dtype=tf.dtypes.float32)\n",
    "# sess = tf.Session()\n",
    "# a = sess.run(testR)\n",
    "# sess.close()\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241a8dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.destruct()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3770d9",
   "metadata": {},
   "source": [
    "# Use one pre-trained model to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeba300e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 10\n",
    "tau = 50\n",
    "T = 3000\n",
    "N_batch = 50\n",
    "N_rec = 100\n",
    "experiment = 'interactive'\n",
    "name = 'basic'\n",
    "\n",
    "task = Checkerboard2AFC(dt=dt, tau=tau, T=T, N_batch=N_batch)\n",
    "\n",
    "network_params = task.get_task_params()\n",
    "network_params['name'] = name\n",
    "network_params['N_rec'] = N_rec\n",
    "network_params['rec_noise'] = 0.1\n",
    "network_params[\"transfer_function\"] = tf.nn.relu\n",
    "network_params[\"output_transfer_function\"] = tf.nn.sigmoid\n",
    "network_params[\"loss_function\"] = \"rt_mask_mse\"\n",
    "network_params[\"rt_mask_mse\"] = rt_mask_mse_07\n",
    "network_params['load_weights_path'] = \"./weights/basic2_w.npz\"\n",
    "network_params['gain_bound'] = [1, 2]\n",
    "model2 = Basic2(network_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51923a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\BU\\ChandLab\\PsychRNN\\psychrnn\\backend\\gain\\gain2.py:117: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 200/200 [01:03<00:00,  3.15it/s]\n"
     ]
    }
   ],
   "source": [
    "trials = 10000\n",
    "batches = int(np.ceil(trials / N_batch))\n",
    "\n",
    "rnn_state = np.zeros((trials, task.N_steps, model2.N_rec))\n",
    "rnn_out = np.zeros((trials, task.N_steps, model2.N_out))\n",
    "\n",
    "coherence = np.zeros(trials)\n",
    "green_side = np.zeros(trials)\n",
    "target_onset = np.zeros(trials)\n",
    "checker_onset = np.zeros(trials)\n",
    "decision = np.zeros(trials)\n",
    "rt = np.zeros(trials)\n",
    "\n",
    "for b in tqdm(range(batches)):\n",
    "    x, y, m, params = task.get_trial_batch()\n",
    "    outputs, states, inputs = model2.test(x)\n",
    "    \n",
    "    start_index = N_batch * b\n",
    "    end_index = N_batch * (b + 1)\n",
    "    rnn_state[start_index:end_index] = states\n",
    "    rnn_out[start_index:end_index] = outputs\n",
    "    \n",
    "    thr = np.where(outputs > 0.7)\n",
    "    \n",
    "    for i in range(N_batch):\n",
    "        index = start_index + i\n",
    "        \n",
    "        coherence[index] = params[i][\"coherence\"]\n",
    "        green_side[index] = params[i][\"side\"]\n",
    "        target_onset[index] = params[i][\"target_onset\"]\n",
    "        checker_onset[index] = params[i][\"checker_onset\"]\n",
    "        \n",
    "        thr_time = thr[1][thr[0]==i][0] if sum(thr[0]==i) > 0 else outputs.shape[1]\n",
    "        thr_unit = thr[2][thr[0]==i][0] if sum(thr[0]==i) > 0 else np.argmax(outputs[i, -1])\n",
    "        decision[index] = thr_unit\n",
    "        rt[index] = thr_time*task.dt - target_onset[index] - checker_onset[index]       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d52485e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onsets = [p[\"onset_time\"] for p in params]\n",
    "onsets = target_onset[-N_batch:] + checker_onset[-N_batch:]\n",
    "rts = rt[-N_batch:]\n",
    "for i in range(10):\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, 3000, 10), inputs[i, :, 0])\n",
    "    plt.plot(np.arange(0, 3000, 10), inputs[i, :, 1])\n",
    "    plt.plot(np.arange(0, 3000, 10), inputs[i, :, 2])\n",
    "    plt.plot(np.arange(0, 3000, 10), inputs[i, :, 3])\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(np.arange(0, 3000, 10), outputs[i, :, 0])\n",
    "    plt.plot(np.arange(0, 3000, 10), outputs[i, :, 1])\n",
    "    \n",
    "    plt.vlines(onsets[i], 0, 1)\n",
    "    plt.vlines(onsets[i] + rts[i], 0, 1)\n",
    "    plt.hlines(0.7, 0, 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c0c7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_side = np.array([gs if coh > 0 else abs(gs-1) for coh, gs in zip(coherence, green_side)])\n",
    "green_decision = np.array([int(dec == gs) for dec, gs in zip(decision, green_side)])\n",
    "checker_df = pd.DataFrame({'trial' : np.arange(trials),\n",
    "                           'coherence' : coherence,\n",
    "                           'coherence_bin' : np.round(coherence, 1),\n",
    "                           'green_side' : green_side,\n",
    "                           'correct_side' : correct_side,\n",
    "                           'target_onset' : target_onset,\n",
    "                           'checker_onset' : checker_onset,\n",
    "                           'decision' : decision,\n",
    "                           'green_decision' : green_decision,\n",
    "                           'decision_time' : rt,\n",
    "                           'correct_decision' : (decision == correct_side).astype(int)})\n",
    "checker_mean = checker_df.groupby('coherence_bin').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acafd25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(checker_mean['coherence_bin'], checker_mean['green_decision'])\n",
    "plt.scatter(checker_mean['coherence_bin'], checker_mean['green_decision'])\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(checker_mean['coherence_bin'], checker_mean['decision_time'])\n",
    "plt.scatter(checker_mean['coherence_bin'], checker_mean['decision_time'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73122118",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "plt.figure(figsize=(15, 8))\n",
    "for i in [0.9,0.7,0.5,0.3,0.1,0]:\n",
    "    a = checker_df['coherence_bin'] == i\n",
    "    groupCo = checker_df.loc[a,:]\n",
    "    RT = groupCo[\"decision_time\"]\n",
    "    plt.subplot(2,3,idx)\n",
    "    plt.hist(RT, bins = np.arange(0,2000,100))\n",
    "    plt.title(\"Coherence: \" + str(i))\n",
    "    idx = idx + 1\n",
    "\n",
    "plt.savefig(\"gain1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117f42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.destruct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc0ab1ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "456.183px",
    "left": "868.667px",
    "right": "20px",
    "top": "3px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
